{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIOtVKjvO8hL"
   },
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import torch, torchvision, PIL, json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, os, seaborn as sns\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdqF4qJdRkmX"
   },
   "outputs": [],
   "source": [
    "# uninstall older PIL version\n",
    "!pip uninstall -y Pillow\n",
    "# install the new one\n",
    "!pip install Pillow\n",
    "# check Pillow version\n",
    "# restart might be needed to use the new version\n",
    "print(PIL.PILLOW_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yShq_fjDR480"
   },
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "# If CUDA is not available, it can be enabled from \n",
    "# Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7JOOVcaTmoi"
   },
   "outputs": [],
   "source": [
    "# Download the Flower Dataset from https://www.kaggle.com/lenine/flower-102diffspecies-dataset\n",
    "# Also, the category to name json file\n",
    "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
    "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
    "!rm -r flower_data || true\n",
    "!unzip -qq flower_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1l6rGTh0TqBD"
   },
   "outputs": [],
   "source": [
    "# Set the training and validation directories\n",
    "data_dir = 'flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "\n",
    "# Paramns\n",
    "scale = 256\n",
    "input_shape = 224\n",
    "mean = [0.485, 0.456, 0.406] # ImageNet parameters\n",
    "std = [0.229, 0.224, 0.225] # ImageNet parameters\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFxGfSv040Wt"
   },
   "outputs": [],
   "source": [
    "# Define the transforms for the training and validation sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                       transforms.RandomResizedCrop(input_shape),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean, std)])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(scale),\n",
    "                                      transforms.CenterCrop(input_shape),\n",
    "                                      transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_NdtXc-IwHw"
   },
   "outputs": [],
   "source": [
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1uNl0nBI0wP"
   },
   "outputs": [],
   "source": [
    "# Define the dataloaders using the image datasets and the trainforms\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sd4jVlzSS2E8"
   },
   "outputs": [],
   "source": [
    "# Define a method to check the images from the dataloaders\n",
    "def imgloader(img):\n",
    "  plt.figure(figsize=(25,15))\n",
    "  img=img.numpy()\n",
    "  img[0,:,:]=img[0,:,:]*0.229+0.485\n",
    "  img[1,:,:]=img[1,:,:]*0.224+0.456\n",
    "  img[2,:,:]=img[2,:,:]*0.225+0.406\n",
    "  plt.imshow(np.transpose(img,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PR9xZS24TPvd"
   },
   "outputs": [],
   "source": [
    "# Check the trainloader data\n",
    "# TODO: Reposition the grid so that it splits the images\n",
    "images,labels=next(iter(trainloader))\n",
    "img=torchvision.utils.make_grid(images[:32])\n",
    "imgloader(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39P6oKc-TX8V"
   },
   "outputs": [],
   "source": [
    "# Check the validloader data\n",
    "# TODO: Reposition the grid so that it splits the images\n",
    "images,labels=next(iter(validloader))\n",
    "img=torchvision.utils.make_grid(images[:32])\n",
    "imgloader(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpSa-7KjRqpJ"
   },
   "outputs": [],
   "source": [
    "# Import category to name JSON data\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eRbjYlDTd0m"
   },
   "outputs": [],
   "source": [
    "# Load a pretrained model of your choice from torchvision.models\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# Check model architecture so you can define your new classifier\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lv80gw22Wtfv"
   },
   "outputs": [],
   "source": [
    "# Define a new untrained feed-forward classifier, using ReLu activations and droptout\n",
    "# Keep input features at 2048, change output features from 1000 to 102 (# of flower categories)\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.2),\n",
    "                            nn.Linear(512, 102),\n",
    "                            nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Map classes to indices to be used for Inference\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "\n",
    "# Check model with the new fc classifier\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54wxR4Xa6N01"
   },
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "# Scales, crops, and normalizes a PIL image for a PyTorch model, returns an Numpy array\n",
    "\n",
    "def process_image(image_path):\n",
    "\n",
    "  # Open the image\n",
    "  from PIL import Image\n",
    "  img = Image.open(image_path)\n",
    "  \n",
    "  # Resize\n",
    "  if img.size[0] > img.size[1]:\n",
    "    img.thumbnail((10000, 256))\n",
    "  else:\n",
    "    img.thumbnail((256, 10000))\n",
    "    \n",
    "  # Crop \n",
    "  left_margin = (img.width-224)/2\n",
    "  bottom_margin = (img.height-224)/2\n",
    "  right_margin = left_margin + 224\n",
    "  top_margin = bottom_margin + 224\n",
    "  img = img.crop((left_margin, bottom_margin, right_margin,   \n",
    "                      top_margin))\n",
    "  # Normalize\n",
    "  img = np.array(img)/256\n",
    "  img = (img - mean)/std\n",
    "    \n",
    "  # Move color channels to first dimension as expected by PyTorch\n",
    "  img = img.transpose((2, 0, 1))\n",
    "    \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0dLKLvh6b8w"
   },
   "outputs": [],
   "source": [
    "# Convert Pytorch tensor and display it\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "\n",
    "  # aesthetics configuration\n",
    "  if ax is None:\n",
    "    fig, ax = plt.subplots();\n",
    "  if title:\n",
    "    plt.title(title);\n",
    "    \n",
    "  # PyTorch tensors assume the color channel is first\n",
    "  # but matplotlib assumes is the third dimension\n",
    "  image = image.transpose((1, 2, 0))\n",
    "    \n",
    "  # Undo preprocessing\n",
    "  image = std * image + mean\n",
    "    \n",
    "  # Image needs to be clipped between 0 and 1\n",
    "  image = np.clip(image, 0, 1)\n",
    "    \n",
    "  ax.imshow(image);\n",
    "    \n",
    "  return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2WOZye46e-G"
   },
   "outputs": [],
   "source": [
    "# Predict top(5) class probabilities using the model\n",
    "\n",
    "def predict(image_path, model, top_num=5):\n",
    "\n",
    "    # Process image\n",
    "    img = process_image(image_path)\n",
    "    \n",
    "    # Model activation for the eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Numpy -> Tensor\n",
    "    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "    \n",
    "    # Add batch of size 1 to image\n",
    "    model_input = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    # CPU transfer\n",
    "    image_tensor.to('cpu')\n",
    "    model_input.to('cpu')\n",
    "    model.to('cpu')\n",
    "    \n",
    "    # Probs\n",
    "    probs = torch.exp(model.forward(model_input))\n",
    "    \n",
    "    # Top probs\n",
    "    top_probs, top_labs = probs.topk(top_num)\n",
    "    top_probs = top_probs.detach().numpy().tolist()[0] \n",
    "    top_labs = top_labs.detach().numpy().tolist()[0]\n",
    "    \n",
    "    # Convert indices to classes\n",
    "    idx_to_class = {val: key for key, val in    \n",
    "                                      model.class_to_idx.items()}\n",
    "    top_labels = [idx_to_class[lab] for lab in top_labs]\n",
    "    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n",
    "    return top_probs, top_labels, top_flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0EIVabB6gqB"
   },
   "outputs": [],
   "source": [
    "# Plot the image with the title and probabilities for the top 5 classes as a bar graph\n",
    "\n",
    "def plot_solution(image_path, model):\n",
    "    \n",
    "    # Set up plot\n",
    "    plt.figure(figsize = (6,10))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    \n",
    "    # Set up title\n",
    "    flower_num = image_path.split('/')[2] \n",
    "    title_ = cat_to_name[str(flower_num)] \n",
    "    \n",
    "    # Plot flower\n",
    "    img = process_image(image_path)\n",
    "    imshow(img, ax, title = title_);\n",
    "    \n",
    "    # Make prediction\n",
    "    probs, labs, flowers = predict(image_path, model) \n",
    "    \n",
    "    # Plot bar chart\n",
    "    plt.subplot(2,1,2);\n",
    "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuCMCzNX6jpW"
   },
   "outputs": [],
   "source": [
    "# Test the model before training the Classifier\n",
    "# Top 5 probabilities should be close to the same size at ~1%\n",
    "\n",
    "image_path = os.path.join(valid_dir, '102/image_08040.jpg')\n",
    "plot_solution(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXga3kacNUVh"
   },
   "outputs": [],
   "source": [
    "# Freeze all model parameters except the untrained newly created classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "   \n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGnZz0ZuNvVK"
   },
   "outputs": [],
   "source": [
    "# Define the criterion and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2xfbIZ7O1Lv"
   },
   "outputs": [],
   "source": [
    "# Set the device on which the training will be performed: cuda or cpu\n",
    "# If cuda is available it's best to use it to improve trainig speed by over 100x\n",
    "device=torch.device((\"cuda\") if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ai_3LdRVQ2yE"
   },
   "outputs": [],
   "source": [
    "# Define the function for training the model and saving the checkpoint when\n",
    "# Test/Validation loss decreases\n",
    "def train_model(checkpoint_file):\n",
    "  \n",
    "    epochs = 100\n",
    "    steps = 0\n",
    "    training_loss = 0\n",
    "    print_every = 20\n",
    "    valid_loss_min = np.Inf\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in trainloader:\n",
    "            steps += 1\n",
    "            # Move input and label tensors to the device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)    \n",
    "            optimizer.zero_grad()\n",
    "            logps = model(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            # Validate model and print results after print_every number of steps\n",
    "            if steps % print_every == 0:\n",
    "                valid_loss = 0\n",
    "                accuracy = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in validloader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        logps = model(inputs)\n",
    "                        batch_loss = criterion(logps, labels)\n",
    "                        valid_loss += batch_loss.item()\n",
    "\n",
    "                        # Calculate accuracy\n",
    "                        ps = torch.exp(logps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                valid_loss = valid_loss/len(validloader)\n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Train loss: {training_loss/print_every:.3f}.. \"\n",
    "                      f\"Test loss: {valid_loss:.3f}.. \"\n",
    "                      f\"Test accuracy: {accuracy/len(validloader):.3f}\")\n",
    "                # Save the model if validation loss has decreased\n",
    "                if valid_loss <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,\n",
    "                    valid_loss))\n",
    "                    model.class_to_idx = train_data.class_to_idx\n",
    "                    torch.save({\n",
    "                      'arch':'resnet152',\n",
    "                      'model_state_dict': model.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer.state_dict(),\n",
    "                      'validation_accuraccy': {accuracy/len(validloader)},\n",
    "                      'class_to_idx': model.class_to_idx,\n",
    "                      'validation_loss': {valid_loss},\n",
    "                      'train_loss': {training_loss/print_every},\n",
    "                      }, checkpoint_file)\n",
    "                    valid_loss_min = valid_loss\n",
    "                training_loss = 0\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfStyT-TfHb4"
   },
   "outputs": [],
   "source": [
    "# Train the model's classifier\n",
    "# After 1 epoch the Accuracy is close to 70% and after 3 epochs close to 90%.\n",
    "# As the increase in accuracy/decrease in test loss happen at a much lower rate,\n",
    "# training should be stopped and new approaches should be used.\n",
    "train_model('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9SAZ4oCYkvZ"
   },
   "outputs": [],
   "source": [
    "# Define a method for loading the checkpoint and rebuilding the model\n",
    "def load_checkpoint(checkpoint_file):\n",
    "  checkpoint = torch.load(checkpoint_file)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "  model.class_to_idx = checkpoint['class_to_idx']\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Nq5VNpFZkRW"
   },
   "outputs": [],
   "source": [
    "# Load the saved checkpoint for further training or inference\n",
    "load_checkpoint('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAen944qYc5i"
   },
   "outputs": [],
   "source": [
    "# Test the model after training the Classifier\n",
    "# Model should be able to predict the correct flower with high accuracy\n",
    "\n",
    "image_path = os.path.join(valid_dir, '102/image_08040.jpg')\n",
    "plot_solution(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gwUndkwgMjl"
   },
   "outputs": [],
   "source": [
    "# The last layes from the CNN are responsible for more richer representations,\n",
    "# so the last layer will be unfrozen before a new training session\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.layer4.parameters():\n",
    "      param.requires_grad = True\n",
    "   \n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TayRj2v6gWv_"
   },
   "outputs": [],
   "source": [
    "# The optimizer will be also changed for variation\n",
    "# learning rate will be dropped by 10x\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_nyj_sgkxQ4"
   },
   "outputs": [],
   "source": [
    "# Start new training session.\n",
    "\n",
    "model.to(device)\n",
    "train_model('checkpoint2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model after training\n",
    "# Model should be able to predict the correct flower with high accuracy\n",
    "\n",
    "image_path = os.path.join(valid_dir, '102/image_08040.jpg')\n",
    "plot_solution(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgH-CslrpIOC"
   },
   "outputs": [],
   "source": [
    "# On the last training session all layers will be unfrozen\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe9B03T5pM7q"
   },
   "outputs": [],
   "source": [
    "# Learning rate will be dropped by 10x\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "af1SEt5KpVb6"
   },
   "outputs": [],
   "source": [
    "# Start new training session\n",
    "\n",
    "model.to(device)\n",
    "train_model('checkpoint3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YthaenZGfpf"
   },
   "outputs": [],
   "source": [
    "# Test the model after training\n",
    "# Model should be able to predict the correct flower with high accuracy\n",
    "\n",
    "image_path = os.path.join(valid_dir, '102/image_08040.jpg')\n",
    "plot_solution(image_path, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flower_Classifier_Colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
